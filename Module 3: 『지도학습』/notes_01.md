# notes_1

*“친구야 Supervised Learning이 모야..?”*

### Supervised Learning에 대해서

---

- Q. Supervised Learning 이란?
    
    Supervised Learning = 지도학습. 머신러닝, 즉 컴퓨터로 하여금 무언가를 학습 시킬 때에는 크게 지도 학습과 비지도 학습이 있는데, 지도 학습은 **문제+정답 페어**를 주어 학습을 시키는 거다.
    
    예를 들어 사진을 주고 강아지와 고양이를 분류하는 모델을 학습 할 때, 이미지와 이미지의 정답 레이블을 가지고 학습을 시키면 **Supervised Learning**이 되는 것이다.
    
    다른 심화 예제로 text classifacation이 있는데, 리뷰 문장을 감정 분석을 할 때 (리뷰가 긍정적인지, 부정적인지) 단어에 각각 점수를 매겨 긍정이면 +를, 부정이면 -를 주어 총합하여 계산하는 방법이다. 
    
    반면 Unsupervised Learning은 정답 없이, 여러 데이터가 주어 졌을 때 규칙을 스스로 찾게 하는 것에 목적을 둔다. 예를 들어 Unsupervised Learning으로 강아지 고양이 이미지 분류를 하고자 한다면, 강아지와 고양이 이미지를 정답 레이블 없이 학습 시키고, 컴퓨터가 스스로 학습한 정보들을 2가지의 분류하여(인간은 이때 분류 방법과 기준을 알기 어려움) 이 분류된 2가지가 강아지와 고양이로 나오면 성공적인 모델이 되는 것이다. 하지만 대체로 정확도가 떨어지고 어렵다.  
    

---

- Q. Classification vs. Regression
    
    이미지를 주어 주어진 10개의 카테고리 중 무엇인지 맞추게 하는 것이 Classification이고, 반면 Regression은 어떤 정답이 숫자로, 혹은 연속적인 실수 변수로 나타나는 것이다. 대표적인 예시로 주가 예측이 있다. 
    
    즉, 고를 수 있는 정답(보기)이 정해져 있는지, 아닌지가 큰 차이점이다.  
    
    일반적으로 Classification을 많이 사용한다! 결국에는 정답 조합이 정해진 문제들이 많기 때문에~
    
    ![3.png](notes_1%20e33cccf07a2045418686d238e154d66a/3.png)
    

---

- Q. Supervised Learning을 수학적 함수 측면에서 설명해 보아라
    
    지도학습은 입력 x를 출력 y로 매핑하는 수학적 함수로 볼 수 있는데, 이때 함수를 f(x)라고 하면, 우리는 정확한 f(x)를 찾기보단 **가장 f(x)와 유사한 함수(정확도가 높은 함수)를 찾는 것**이다.
    
    즉 모든 함수가 아닌, 함수 클래스 G라는 것을 정해서 이중 가장 f(x)와 근사한 것을 찾는 것이다.
    
    이때 어떻게 가장 유사한지는 Pointwise Loss함수라는  $L$ 함수(손실 함수)를 정의하여(값이 작게 나올수록 손실이 적다 = 정답과 유사하다) 판단한다.
    

---

- Q. 손실 함수에 대해 설명해 보아라
    
    모델이 예측한 값과 실제 정답 사이의 차이를 수치화하여 모델이 얼마나 틀렸는지 숫자로 보여준다. 
    
    그렇다면 어떤 방식으로 오차를 계산하는지, 예를 들어 단순히 뺄셈, 혹은 점과 점 사이의 거리 계산, 등 중에서 정해야 하는데 이때 보편적으로 Mean Squared Error (평균제곱오차)를 사용한다.
    
    Mean Squared Error은 예측값과 실제값의 차이를 제곱해 평균화 하는 것이다.
    

*“리니…리니어 뭐..? 리니어 리그레션? 그게 뭐야?”*

### **가장 기초적이면서 중요한 Linear Regression에 대해서**

---

- Q. Linear Regression 이란?
    
    Linear Regression = 선형 함수
    
    여기서 “선형” 뜻을 알아야 선형 함수를 이해할 수 있는데, 우선 직관적으로 선의 형태… 직선? ax + b? 로 생각할 수 있다. 틀린것은 아니지만, 2차원, 즉 입력변수가 한가지 일 때만 직선 형태이고, 다차원 공간에서는 **평면 또는 초평면** 형태를 띈다.
    
    ![4.png](notes_1%20e33cccf07a2045418686d238e154d66a/4.png)
    
    선형 회귀의 목표는 주어진 데이터를 기반으로 β₀과 β₁, β₂, ..., βₙ(회귀 계수)을 찾는 것이다.
    
    왜 변수가 여러개인데 일차식으로 표현이 가능한가? 에 대해 의문이 있다면, 아무리 많은 변수가 있더라고 수식을 전개해서 미분 과정을 거치면 결국 일차식으로 표현 가능하기 때문이다. 
    
    이를 위해 Mean Squared Error를 사용해서 손실 함수를 계산할 수 있다. 다시한번 말하지만 손실 함수에는 Mean Squared Error외에 다른 방법을 사용해도 되지만, Mean Squared Error이 여러 이유로 보편적으로 사용된다.
    
- overfitting 과 underfitting
    
    이미 전에 필기 했다.